{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees\n",
    "\n",
    "This workbook will implement decision trees for the binary classification problem of breast cancer diagnosis.\n",
    "It involves data manipulation/visualisation, hyperparameter selection, recursion, and building a prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn import datasets as ds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "The first step of any machine learning problem is to load the data. we will be using a built-in dataset provided by the scikit learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = ds.load_breast_cancer()\n",
    "\n",
    "x = data_all.data\n",
    "y = data_all.target\n",
    "\n",
    "y_names = data_all.target_names \n",
    "\n",
    "feature_names = data_all.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Wisconsin (Diagnostic) Database\n",
    "A description of the dataset used is provided here.\n",
    "\n",
    "Data Set Characteristics:\n",
    "    :Number of Instances: 569\n",
    "\n",
    "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
    "\n",
    "    :Attribute Information:\n",
    "        - radius (mean of distances from center to points on the perimeter)\n",
    "        - texture (standard deviation of gray-scale values)\n",
    "        - perimeter\n",
    "        - area\n",
    "        - smoothness (local variation in radius lengths)\n",
    "        - compactness (perimeter^2 / area - 1.0)\n",
    "        - concavity (severity of concave portions of the contour)\n",
    "        - concave points (number of concave portions of the contour)\n",
    "        - symmetry \n",
    "        - fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "        largest values) of these features were computed for each image,\n",
    "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
    "        13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "        - target class:\n",
    "                - WDBC-Malignant\n",
    "                - WDBC-Benign\n",
    "\n",
    "    :Summary Statistics:\n",
    "\n",
    "    ===================================== ====== ======\n",
    "                                           Min    Max\n",
    "    ===================================== ====== ======\n",
    "    radius (mean):                        6.981  28.11\n",
    "    texture (mean):                       9.71   39.28\n",
    "    perimeter (mean):                     43.79  188.5\n",
    "    area (mean):                          143.5  2501.0\n",
    "    smoothness (mean):                    0.053  0.163\n",
    "    compactness (mean):                   0.019  0.345\n",
    "    concavity (mean):                     0.0    0.427\n",
    "    concave points (mean):                0.0    0.201\n",
    "    symmetry (mean):                      0.106  0.304\n",
    "    fractal dimension (mean):             0.05   0.097\n",
    "    radius (standard error):              0.112  2.873\n",
    "    texture (standard error):             0.36   4.885\n",
    "    perimeter (standard error):           0.757  21.98\n",
    "    area (standard error):                6.802  542.2\n",
    "    smoothness (standard error):          0.002  0.031\n",
    "    compactness (standard error):         0.002  0.135\n",
    "    concavity (standard error):           0.0    0.396\n",
    "    concave points (standard error):      0.0    0.053\n",
    "    symmetry (standard error):            0.008  0.079\n",
    "    fractal dimension (standard error):   0.001  0.03\n",
    "    radius (worst):                       7.93   36.04\n",
    "    texture (worst):                      12.02  49.54\n",
    "    perimeter (worst):                    50.41  251.2\n",
    "    area (worst):                         185.2  4254.0\n",
    "    smoothness (worst):                   0.071  0.223\n",
    "    compactness (worst):                  0.027  1.058\n",
    "    concavity (worst):                    0.0    1.252\n",
    "    concave points (worst):               0.0    0.291\n",
    "    symmetry (worst):                     0.156  0.664\n",
    "    fractal dimension (worst):            0.055  0.208\n",
    "    ===================================== ====== ======\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
    "\n",
    "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
    "\n",
    "    :Donor: Nick Street\n",
    "\n",
    "    :Date: November, 1995\n",
    "\n",
    "This is a copy of the UCI ML Breast Cancer Wisconsin (Diagnostic) dataset from https://goo.gl/U2Uwz2\n",
    "\n",
    "Features are computed from a digitized image of a fine needle\n",
    "aspirate (FNA) of a breast mass. They describe\n",
    "characteristics of the cell nuclei present in the image.\n",
    "\n",
    "Separating plane described above was obtained using\n",
    "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
    "Construction Via Linear Programming.\" Proceedings of the 4th\n",
    "Midwest Artificial Intelligence and Cognitive Science Society,\n",
    "pp. 97-101, 1992], a classification method which uses linear\n",
    "programming to construct a decision tree.  Relevant features\n",
    "were selected using an exhaustive search in the space of 1-4\n",
    "features and 1-3 separating planes.\n",
    "\n",
    "The actual linear program used to obtain the separating plane\n",
    "in the 3-dimensional space is that described in:\n",
    "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
    "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
    "Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server:\n",
    "\n",
    "```\n",
    "ftp ftp.cs.wisc.edu\n",
    "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "```\n",
    "\n",
    "### References\n",
    "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
    "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
    "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
    "     San Jose, CA, 1993.\n",
    "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
    "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
    "     July-August 1995.\n",
    "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
    "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
    "     163-171.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prepare/Split data\n",
    "The bellow code block splits the data and the targets into training and test sets; 60% for training, 40% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 341\n",
      "Test set size: 228\n"
     ]
    }
   ],
   "source": [
    "split = int(x.shape[0] * 0.6)\n",
    "\n",
    "x_train = x[:split,:]\n",
    "y_train = y[:split]\n",
    "\n",
    "x_test = x[split:,:]\n",
    "y_test = y[split:]\n",
    "\n",
    "print('Training set size:', x_train.shape[0])\n",
    "print('Test set size:', x_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation\n",
    "\n",
    "Since our data has a feature dimensionality of 30, it is difficult for us to visualise it. We visualize data by using a dimensionality reduction technique called Principal Component Analysis (PCA). \n",
    "\n",
    "Given an array in `R^{nxd}` (a matrix of size `n X d` with real entries) with `n` and `d` being the number of data points and the feature dimensionality, respectively, PCA will output an array in `R^{nxm}`, with `m<d`. \n",
    "\n",
    "In order to be able to visualise the data on a 2D plot, we choose `m=2` (`m=3` is also a possibility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n",
      "(569, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2df5gcZZXvP2cmP2YCSUhCgMQkJLubXYwwRhiCLFyJBkKIIOpiQnSXIIuTuCBXLq7iugt5cFdRWdGIlxABoyvGycUEUEEC2d0LYoJO3DBAkAUhkDG5JGRwCGbyY2bO/aO6Zmpqqrqru6p/1vk8zzzdXV39vm9X0t/31HnPe46oKoZhGEbtU1fuARiGYRilwQTfMAwjJZjgG4ZhpAQTfMMwjJRggm8YhpEShpV7ANk49thjdfr06eUehmEYRtWwdevW11V1YtB7FS3406dPp62trdzDMAzDqBpE5JWw98ylYxiGkRJM8A3DMFKCCb5hGEZKqGgfvmEYtc2RI0fo6Ojg4MGD5R5K1dHQ0MCUKVMYPnx45M+Y4BuGUTY6OjoYPXo006dPR0TKPZyqQVXZt28fHR0dzJgxI/LnzKVjGMWmfR3cejKsOMZ5bF9X7hFVDAcPHmTChAkm9nkiIkyYMCHvOyOz8A2jmLSvg59cA0e6ndddO53XAE2LyjeuCsLEvjAKuW5m4RtGMdl004DYuxzpdo4bRokxwTeMYtLVkd9xo6SICNddd13/61tuuYUVK1Yk3s+XvvSlQa//8i//MvE+omCCbxjFZOyU/I4bJWXkyJGsX7+e119/vaj9+AX/l7/8ZVH7C8ME3zCKybwbYHjj4GPDG53jRkEsvmMzi+/YnEhbw4YNo6WlhVtvvXXIe3v37uWv/uqvOP300zn99NN54okn+o+fd955nHrqqSxbtowTTzyxf8L44Ac/yGmnncY73vEOVq9eDcD1119Pd3c3s2fP5mMf+xgARx99tPNdFi/mwQcf7O/z8ssv58c//jG9vb38/d//PaeffjpNTU3ccccdiXxfVLVi/0477TQ1jKrnqVbVr79D9caxzuNTreUeUcWwffv2vD+zaNUvddGqXybS/1FHHaVdXV164okn6h/+8Af92te+pjfeeKOqqi5ZskQff/xxVVV95ZVX9KSTTlJV1auuukq/9KUvqarqQw89pIDu3btXVVX37dunqqoHDhzQd7zjHfr666/39+PvV1V1/fr1etlll6mq6qFDh3TKlCl64MABveOOO/SLX/yiqqoePHhQTzvtNH3ppZeGjD/o+gFtGqKpkaN0RORu4EJgj6qenDn2NeAi4DDwO+DjqvqHgM/uAPYDvUCPqjbHnagMo2poWmQROQngWvVPvtw56HXrsjNjtTtmzBguu+wyVq5cSWPjwN3Yo48+yvbt2/tfv/nmm+zfv59f/OIXbNiwAYAFCxYwbty4/nNWrlzZ/97OnTt54YUXmDBhQmjfF1xwAddccw2HDh3i5z//Oe95z3tobGxk48aNtLe3c++99wLQ1dXFCy+8kFfMfRD5hGWuAW4Dvu859gjweVXtEZGvAJ8HPhfy+feqanEdZYZhGAXw6U9/mlNPPZWPf/zj/cf6+vrYvHnzoEkAHK9IEP/5n//Jo48+yubNmxk1ahRz587NGSff0NDA3Llzefjhh2ltbWXJkiX9fXzrW9/i/PPPj/nNBhPZh6+qjwGdvmMbVbUn83ILYCtRhmEUhdZlZ9K67EzOmDGeM2aM73+dBOPHj2fRokXcdddd/cfmz5/Pbbfd1v9627ZtAJx99tmsW+dsntu4cSNvvPEG4Fjh48aNY9SoUfz2t79ly5Yt/Z8dPnw4R44cCez70ksv5bvf/S6PP/54v8Cff/753H777f2f+e///m/++Mc/xv6eSS7aXgE8FPKeAhtFZKuItCTYp2EYRiJcd911g6J1Vq5cSVtbG01NTcyaNYtVq1YBcOONN7Jx40ZOPfVUHnroISZNmsTo0aNZsGABPT09NDU18U//9E+8+93v7m+rpaWFpqam/kVbL/Pnz+exxx7j3HPPZcSIEQBceeWVzJo1i1NPPZWTTz6ZZcuW0dPTM+Sz+SJhtyeBJ4tMB37q+vA9x78ANAMf1oAGRWSyqu4SkeNw3ECfytwxBPXRArQATJs27bRXXgnN5W8YRpXz3HPP8fa3v73cw8iLQ4cOUV9fz7Bhw9i8eTOf/OQn+63/UhN0/URka9g6aezUCiKyFGcxd16Q2AOo6q7M4x4R2QDMAQIFX1VXA6sBmpubo89GhmEYJeDVV19l0aJF9PX1MWLECL7zne+Ue0iRiSX4IrIAZ5H2HFU9EHLOUUCdqu7PPJ8P2L5ywzCqkpkzZ/Jf//Vf5R5GQUT24YvIWmAz8Bci0iEif4sTtTMaeEREtonIqsy5k0XE3U1wPPALEXkK+BXwM1X9eaLfwjAMw8hJZAtfVZcEHL4r4JjrwlmYef4S8M6CRmcYhmEkhqVWMAzDSAkm+IZhGCnBBN8wDCMGq1at4vvfdxIQrFmzhl27dvW/d+WVVw5Kz1BurOKVYRhGDJYvX97/fM2aNZx88slMnjwZgDvvvLNcwwrELHzDMKqHhOsD79ixg5NOOomlS5fS1NTEJZdcwoEDB9i0aRPvete7OOWUU7jiiis4dOgQ4KQ6njVrFk1NTXzmM58BYMWKFdxyyy3ce++9tLW18bGPfYzZs2fT3d3N3LlzaWtr4/bbb+ezn/1sf79r1qzhU5/6FAA/+MEPmDNnDrNnz2bZsmX09vbG+k7ZMME3DKM6cOsDd+0EdKA+cEzRf/7552lpaaG9vZ0xY8bw9a9/ncsvv5zW1laefvppenp6uP322+ns7GTDhg08++yztLe384//+I+D2rnkkktobm7mnnvuYdu2bYOSrl1yySWsX7++/3VrayuLFy/mueeeo7W1lSeeeIJt27ZRX1/PPffcE+v7ZMME3zCM6qBI9YGnTp3KWWedBcBf//Vfs2nTJmbMmMGf//mfA7B06VIee+wxxowZQ0NDA1deeSXr169n1KhRkfuYOHEif/Inf8KWLVvYt28fzz//PGeddRabNm1i69atnH766cyePZtNmzbx0ksvxfo+2TAfvmEY1UGR6gOLSKTzhg0bxq9+9Ss2bdrEj370I2677Tb+/d//PXI/ixcvZt26dZx00kl86EMfQkRQVZYuXcqXv/zlQoefF2bhG4ZRHRSpPvCrr77K5s1OMZW1a9dy7rnnsmPHDl588UUA/u3f/o1zzjmHt956i66uLhYuXMg3vvGNwIRpo0ePZv/+/YH9fPjDH+a+++5j7dq1LF68GIB58+Zx7733smfPHgA6OzspZsJIE3zDMKqDItUHfvvb3873vvc9mpqa6Ozs5Nprr+W73/0uH/nIRzjllFOoq6tj+fLl7N+/nwsvvJCmpibOOeecwDq4l19+OcuXL+9ftPUybtw4Zs2axSuvvMKcOXMAmDVrFv/8z//M/PnzaWpq4rzzzmP37t2xvk828kqPXGqam5u1ra2t3MMwDKNI5J0euX2d47Pv6nAs+3k3xCofuWPHDi688EKeeeaZgtsoJyVPj2wYhlEyrD5wLMylYxhGapk+fXrVWveFYIJvGEZZqWS3ciVTyHUzwTcMo2w0NDSwb98+E/08UVX27dtHQ0NDXp8zH75hGGVjypQpdHR0sHfv3nIPpepoaGhgypT8QlIjC76I3I1Tu3aPW8RcRMYDrcB0YAewSFXfCPjsAuCbQD1wp6renNcoDcOoSYYPH86MGTPKPYzUkI9LZw2wwHfsemCTqs4ENmVeD0JE6oFvAxcAs4AlIjKroNEahmEYBRNZ8FX1MaDTd/hi4HuZ598DPhjw0TnAi6r6kqoeBn6U+ZxhGIZRQuIu2h6vqrsBMo/HBZzzNmCn53VH5phhGIZRQkoRpROUmSh0SV5EWkSkTUTabCHHMAwjOeIK/msiMgkg87gn4JwOYKrn9RRgV8B5AKjqalVtVtXmiRMnxhyeYRiG4RJX8B8AlmaeLwXuDzjn18BMEZkhIiOASzOfM4yaZfEdm1l8x+ZyD8MwBhFZ8EVkLbAZ+AsR6RCRvwVuBs4TkReA8zKvEZHJIvIggKr2AFcDDwPPAetU9dlkv4ZhZEi4BJ5h1BKWLdOoHdwSeN6qSMMb4aKVJUu45Vr1T77sBLSdMWM8AK3LzixJ/4aRLVumpVYwaocilcAzjFrBUisYtUORSuDlg2vJu5a+WfZGJWEWvlE7FKkEnmHUCmbhG7XDvBuCffgxS+AVgln2RiViFr5ROzQtchZox04FxHks4YKtYVQ6ZuEbtYWVwDOMUMzCNwzDSAkm+IZhGCnBBN8wDCMlmOAbhmGkBBN8wzCMlGCCbxiGkRJM8A3DMFKCCb4RjKUZNoyawzZeGUPxpxnu2um8BtvUZBhVjFn4xlAszXBeWHUro1qILfgi8hciss3z96aIfNp3zlwR6fKcU/psVkZ0KiDNsGEYyRPbpaOqzwOzAUSkHvg9sCHg1MdV9cK4/RkRaV/nWORdHU564Hk3RHfHjJ3iuHH8SJ3j08+3vRrFX93KcuAblU7SLp15wO9U9ZWE2zXywfXBd+0EdMAHH3Xhdd4NTlphP9pbWHuGYVQESS/aXgqsDXnvTBF5CtgFfMYKmReRbD74KFa5e457hyB1GbEvsL0axapbGdVGYoIvIiOADwCfD3j7N8CJqvqWiCwE7gNmhrTTArQATJs2LanhpYskfPDeNMMrjonfnmEYZSdJl84FwG9U9TX/G6r6pqq+lXn+IDBcRI4NakRVV6tqs6o2T5w4McHhpYikS/01jku2vRqjddmZZt0bVUGSgr+EEHeOiJwgIpJ5PifT774E+za8BPngCy31174ODu0ferx+RFlKBxqGUTiJuHREZBRwHrDMc2w5gKquAi4BPikiPUA3cKmqahJ9GwH4ffBxomo23QR9R4YeH3F0qv33hlGNJCL4qnoAmOA7tsrz/DbgtiT6MiKSVKm/MD999xvx2zYMo6TYTlsjO7nWAyznjmFUDSb4RnayrQfEjfc3DKOkmOAb2WlaBBethLFTAXEeL1rpHLecO4ZRVVi2zFomTnoFL2HrAZZzxzCqChP8WqUUKY7Dcu40jnP8+XEnGsMwEsVcOrVKKdwtQf79uuFw+C3z6xtGBWKCX6uUwt0S5N8fORp6Dw8+r4r9+pbr3qglzKVTq4S5W5JOh+D371veHcOoWEzwa5V5Nwz24UPh6RXyoVQTTZGxXPdGLWIunVolWzhlMUkyj49hGIkilZzSprm5Wdva2so9DCNfkgoHrQDMsjeqDRHZqqrNQe+ZS8dInqTy+Bg1i02k5cEEv5qoIcu5WjBBMmoJE/xqoRQbqYyCMGs1OrYYXl5s0bZasLw1hmHExCz8asHy1gCVZRGatZo/Vvi9vCRi4YvIDhF5WkS2iciQsBpxWCkiL4pIu4icmkS/qcLqyhqGEZMkLfz3qurrIe9dAMzM/J0B3J55NKJgdWUr0po2a7Vw7FqVh1L58C8Gvq8OW4BjRGRSifqufmqsrmxe+WkyFbXW7r6A2167jA/U/aK4gzOMGiYpC1+BjSKiwB2qutr3/tsA7377jsyx3Qn1X9ukta6sJzKpDpjYt4evjriLPxt7NNcs+0K5R9ePWatGtZCU4J+lqrtE5DjgERH5rao+5nlfAj4TuMVXRFqAFoBp06YlNLwEKGcMfFrz0wREJjVwiCX71wCVI/iGUS0k4tJR1V2Zxz3ABmCO75QOYKrn9RRgV0hbq1W1WVWbJ06cmMTw4lPu2q1pzU8TcmczsW9viQdiGLVBbMEXkaNEZLT7HJgPPOM77QHgsky0zruBLlWtHndOuWPgS50ILeM3Z8UxzmNCE1vrmTtpPfAJXmr4GL8e9WnndTZ3SNgdTJXd2RhGpZCES+d4YIOIuO39UFV/LiLLAVR1FfAgsBB4ETgAfDyBfktHJcTAlyo/TbF29Ab443O2W64Uz4ZRo8QWfFV9CXhnwPFVnucKXBW3r7JRIz70SOS6myl0HSNbu2FtuMctf5BhJILttI1CmizN0LuZnfEs/0LvkvK8s7GYeMMIx3LpRKFcxUTKQdhdi9THW8cwf7xhlB2z8KNSTB96JaU9Drub8Yu9S9R1jKTukkKuVSXuxDWMSsMs/HJT7pBPP2F3M2OnBp8f1UJP4i6p0q5VBZPXbmYjNZiFX24KWcwsNmF3M3Et9Lh3SVmuVeu1TiRwHMve7gqMWscEv9T4XRJB0T8w2FVSCS6fSoiYqYTw2Aonra6ttHzPuJjgl5KgGHeEwCwTrqsk6DPrW+DVLXDh1wfO8QrxzPnwwsbkhbnctWojhMfGsezTJpJG+jDBLyVBLokgsfe6SsI+03Y3THu389I/IbTdNXBqrvDJoLsHt9+EJ4zYQhqw8HuQkTTUYnhsgaQtZbNN1vlhgl9KsroeMpb+2KmDBTb0MzoQEhkWQeMStiYQdPdw/1WgOpCOuQy1c0N/tJn+9973BSb07WVX3wS+2rOI1zZPhc2b8/qRe/uoRpGsprEalUM6Bb9cPvHGcdDdGfJmRuyv9aUhyurnd11CEQiaOILuHnoPDz0v5iJyLissL/FqWsTVm6cOas8q6QwlLRNBNU7W5SR9gl+sXDFR+g2qWuUlSJTn3QDrPxF8vtTDmMnhE4KXoPDJfBY7S7AwGjQxbN/9JrMmjRn0Q47zI882+VSDWJgLw4hD+gS/XGGQYVWrvASJctOicMHX3uANTX7Cwiez3T1EGVtEwgTaL171AqNGpu+/pBEfm/Cikb5fV7lC+3K1ny2mfezUkOiUqQOTVNikAOEbnIImi/oRg334ucYWk+273+x/PmrkMGZNGjPo+P6DPTz5cmegJZvvj9zbRrVaxubCMOKQvp225cjp0r4OJMulbhyffddprgIoTYuy7ISdGt5u0O7Xi78NH/zfRckb5HebuM/rM8sQ+w/2AIMngWLguooMI22kz8IvdeZLd81Ae8PP6fG5Y4IWlS9amX2hudDvFRZbX+RFbNdCdUXei9dnH8dPH+Y6Gt0wrP/9qO1XmkVdKeMwqov0CX6pd4wGxtH78K4hhC0qX7RyaASPl0rYCRsDrwgXG3eS8S4KG0YaEKc2SWXS3NysbW1t5R7GYPIN6VxxDCH12n0IrPiDU1IwzF+fTfCrlFNWPAzQL7pxBN9vyZ8xY/ygNt2+XMEf3TCs/7n/3KhtGkalISJbVbU56L3YFr6ITAW+D5wA9AGrVfWbvnPmAvcDL2cOrVfVEhWETZBCQjqjRsK4awjZCpC0r4tvsZd6D0KO/g4ccgQ3CQHN5Zf3WvKuZe8KeRqoNLeUUXqScOn0ANep6m8yxcy3isgjqrrdd97jqnphAv2Vj0JCOufd4OS+yWble33t2SaI+6+Chz4H3W9ET4PgFdzGcc5egFLtos0yQS7ObJ7qzVyWJMTI75rxt+X16bvrBLn6tagYo5ZIoqbtbmB35vl+EXkOeBvgF/zqp5CQzmxx9C7eylHZ4up7Dw/s1O3aCff9HYgM7I51UyO4k0LjODj81sD7Qbt8/esHuaz/LOcMEcUsE+T2rn8ddDhO1Izri/e6arJRKaJdqknENmsZLoku2orIdOBdwJMBb58pIk8Bu4DPqOqzIW20AC0A06ZNS3J48QmzvhvH5fhcSBy9l66dzsTQOB7e+dHBCdDCCNrI5Z0UQtM4+PvuiOauytellWWCdK1xV4SSXDjNp62oomfiaNQCiS3aisjRwP8F/kVV1/veGwP0qepbIrIQ+KaqzszVZkkXbfst151OygLtHZrIrH2dY1X7hbZ+hBO/HuhK2enE4Gtf9LEMb4RhjdEFOy5uDH+uxeKQBeW9dcdx9fHfH7qweeATOdt0F1KfXnF+QUMPCrn0p2KoNMq1EGyWfTrItmibyMYrERkO/Bi4xy/2AKr6pqq+lXn+IDBcRI5Nou9EGFQ6j4GYeX8JvaZFMHL00M/3HoYNywfOG9KeT+wbx2cfj2tB+zdbFQN3/SDbYnH/8+BzJvTtDf5srg1jONZ4ucIi01QG0DabGZBMlI4AdwHPqerXQ845AXhNVVVE5uBMNPvi9p0Y2WLl/Yuy3W8En6e9jv88V3sAI45y/rK5ebrfgA+vHrzgerAr+wauiPQhzkzv9cG7dyNBfGWGMx6pC+y/buyUkAVQ59FNZ1wXsC4Q19qsxkXVco250u98jOKThA//LOBvgKdFZFvm2D8A0wBUdRVwCfBJEekBuoFLtZI2AOTKc+N9P1sUTe/hzIJpDldMV4cj5tmSno2dMngXrOtOSkDwUVg8+SEAWpsyApAtmsj9PgF9ewuQ+C1IR9Cm8uSBbwBwxqTxsBlam+J/hTikaREzTd/VyE0SUTq/IEdSdlW9Dbgtbl9FI1esvDfPzrwbHEs+KG88RPO7u2L+6pbwxdmZ8wdHxIRY16ElErOwSycMvPD2EbGdXuoQdEgBkriumThiVG4BK2Ts5R5zLWETWTTSl1ohiGyhkP58NK9uCRf7KHjbe2Fj+Hltdw2eDEIte3XWBLo7iSL+BxnJ+nFXOD8Mf9RNRARlyaSHBhZKd7/JQh7nU31rmSyvs/em41g7+nJar/0CQMn95BZbP0BS3zUN1yoNmOC7Fu6R7oHonGxROm13x+vPG3MfNRd9LiKKPY3jWT3iSp4Y9T6ugWh5fgKoaxxH64FP0NfQwb66iWwdOYe53Y/QUHcIgIl9e2jp+ia0zwwM18yV3CxMXCpRdMxlUl7s+udHugXfb+Fqr2OBh6UD3nQT+bpPAvHGrydGhHF97mWuAfp7zlVj178zF6BuuLOZq7uTOhxxX9D9syH9N3BoyA5kf7bKpMn3x58mUYhr2Zug1gbpFvx8UiW0r0vOInf7KSVB+fLD1i68sff+nbWH/xiwThEy2YRMKN5slZDd7eDNaFmJopMm91AlYtc/P9It+FFTJbh3AtVKWF78wLULcSaBW08ecGd5J78Vx0TvN7PYHZatMmmCfvxurH1UITDhGIwJam2RbsEPtXB91a8K9HVXDnVOuOj6lsGx94Ny6O9k0DpAWNqEiNk/DzKS1SzBO01GSW7m3wzlzWZZ6C7a7bvfzEv0c5FEuUUjWez6RyN9JQ69ZNsJ2r7OsXJXjE3WlVMOjrhuGB3I2fOVGQPplq99JuPy8blmvAvMLkHXzIMqdPQdy+qx/5MnRr1v0Hv+EofFwmuVPvlyJ/sP9vSLfhjuRPPky539NXTzjS6q5Z27pfq3M4pLbVr4UXO+h1WJgoLCFauK7s7BFnwu95Y/zXLItVERrpv8A1qXnUmYEyxIOMLyy8TJM+PdCOYVfVvANNJK7Ql+vhkdg2q63npybYu9i3eBOpt7y39Ns4SB7qubmMjQXLEudDOX6x7ypk3O1lYSNXRtIjAqndoT/EKKlPjJlWohH+pHOH6OoFTGlYD7XbMVQQ9cw1D68PkEhzcy8aJ/GUjXQHTx8wsuDIh+XOFMKoNm2KRQq24co/aoPcEvpEiJn6hlCXO2M3XARRQlx045cBeoA9xbK1nCE5unsrarI3CxR3BSI0/s2xupXGIU8XdF3rXK47phwqz6sLHESetglr1R6dSe4EeNvMnGzPnRCpBk49iTYN8LzgKp1CeyX6tghh/lPB75o++4L1zT497qj38fBf+PCUzm9SHN/r7vWM4++I0BP3uAZe91c7jx9NmYNWlMJN97NnENWw/IRj5iXQxBt8nCKAW1J/gz52fSH3gUNiwOPYxsOW6i8vpvB54nkeEyFn3O7mGItJjt9X0/+XInN9ct4ubhdzJKBnIIdTOCr/ZEr4PrbS+buOXrew/rK4wwf3vYeZYMzaglakvw29fBUz9ksDktMGWOI3T+OPQwkvThVwLuGsa1z+Rcx/CLLcADfWfDEbh+xDpOYB91Y6fQOO8GXts8lTMIF25ve96dsn5L3y+uXtH3+96jLJDmivf34nchlSvRWzEWfO2uwfBTW4IfsrjIy4+Rc0ORl6R8+JVErkksE3a5tquD3TqBr9QtcoQ+w8/0bF6b9AHAIyCbo4mjK9phIh6Et6BKVILKHQa16z3XxTsZQXj6hyQwITbKRWI1bYtB3jVtVxxDZGe5N1+Mn5/+r6FuoVqhcTxc8JWh9Xd9EToHdATXH7mSB/rOpj5T7eB3X35/wd367xzOmDF+iOXvPZZLDMPy7kC47z7bGkDYBBBlH0C+Ap5t7Ela9qWumWtUBtlq2iZi4YvIAuCbQD1wp6re7HtfMu8vBA4Al6vqb5LoexD5WOZBG4rGTnHWAIa4hWqI7k64b7nz3BuZ47szGiWH+eywdfxH3dzQAuP5ipRX3ItBPmGT+eTKzzcfTxjZ3DdWb9YoBUnUtK0Hvg2cB3QAvxaRB1R1u+e0C4CZmb8zgNszj8kSlgwsSLyDNhR17axdy95LX68TJuoKfoi7Z7IkV3Y4SkZMINLCbrbjXvLxjxci5kn635Ms5J7rWvuPGekhCQt/DvCiqr4EICI/Ai4GvIJ/MfD9TB3bLSJyjIhMUtXdCfQ/QFCqBNdiz2NDUSro7nRcYGOnOKkSAvYI7NIJzJo8JjQkMpvQRREWr+V94FBPJCs3SrtJbIjyWvZJLahmu3soxqKt3TUYfpIQ/LcBXj9KB0Ot96Bz3gYMEXwRaQFaAKZNmxZ/dNPe7fwFhSOub8mvLamH6WdD50sDOWUOvxWv5GFZUY8LrA7o63/ngOYXdhmVbKGYLkntsC32hqhK33AVFAll6R/STRKCH1TA3G8mRznHOai6GlgNzqJtXiMJy6Nz0crgBdpConEm/BksfWBwn+s/kV8bFUkfbzKao3mrvzj5f4yYyyzCd6NGWTg9ZcXDOUMrT1nxcP9i7uiGYRw4NDRffjkEq1iCHpRWuZiLtlE3vRm1TxKC3wF4yylNAXYVcE588q1gddi38zQX2juwA/fCrw8cH37U0F2sVcihukY+cfz/6ReK+ohulqTpVXL68fMZV5iIJiWy1WAle0NjoTrGbCRPEoL/a2CmiMwAfg9cCnzUd84DwNUZ//4ZQFfi/nvIv4JVoRkxt65xBL99Hdz3d5WbGA0nb5sE3ZwzTvMAAA/8SURBVF8FMLFvD61n7mQxAeUQA8jmnhndMIz9B3sGxbN7N1a5x7yf8YdpBvUVxS+fS9Ty9e3ns0Ac17+fBJXuajLKR2zBV9UeEbkaeBgnLPNuVX1WRJZn3l8FPIgTkvkiTljmx+P2G0ipKli5qRIe+lxFiz2N4+nuPsAoDkb/zE+uYfqRK3mQ/1HUzUdBRLFCk9gYVYrNVcVsNw6VNBaj9CQSh6+qD+KIuvfYKs9zBa5Koq+shCU9mzl/8OucfvuQUE4v7evKm/1S6sNz9LhZOpsWcf+Kj3ApGwMXUQI50s1n6lrZcfz7C46Zj2phBvmy45DLz+++TqqmbtBdSdIiH6c9E3fDT22lVghLeuY/nk0sgUihmeVeqNVeJ7zUH2560UpnvSJTovFSdkYX+wwT+/aW1d+brT934TGJSB439YK/jbjf283uaRExRqVRW4If1Ydf9uyVCeCmSAgKN/WsLWQV+7FT46eS9uDPlRNH4MKsc/9dh98fn22i8rdV6IJ00Fi8RVaSSMBmYZRGMagtwY/qww8TumqiuxNe3RIcbhplbUHqs1e5In9x2b77zcCQykrFH6aYlMjaoqlRqdSW4OcQsKznVSNtdzubynwhp9rdmduNo73hRdyjloLM4E+M9uTLnYHx91Hbctvwvg6yzt3duYX60HPlxA+jFIJuk4ZRDGpL8KMKmPv6J5+u8vh5db4rDP7OEdhbdxwTIbiIe54EWfaFWPpRNgj5I2yipmTIhj9DZzHi8024jUqgtgQf8hSwvtynVDpdOzMpIgby/eey7vuAtaMv55qEhuAKtDcPfaEbfaJ8zjuZ9Ga+dj6Fyr3C7p0sihGfHxebIIwkqT3Bj0rcWPyKInoGij6FjaMu5IlR70tM8F1ROmXFwxw41NM/AUQV0HxSAcyaNIa2HZ3Uy4DY++vg+tsNEk2/G6pth9N38/TxiYpsvusCdidgFJP0Cn62ClBuHHu5Qy8TRBX+SAP/cOQKXjvmA4HnxBUbV6Bbl53JKSseBgrf3JQr/45blGV0w7BExNGdPNz1ByC0DoBhVCvpFfywiJ7G8QORLzUk+CLwJkfzHyPm8nSM3O+50hK76X7z2dwU1XfuteJdgQ5aK4gy2bhjbdvR2d+Wy4FDPYwaGf+n4U8d4R9D0LkWhmkUk7pyD6BszLsB6oYPPX74LSeOvYoJq1p5AvsC3STenOxu0rJ8/dl/+vmf8aef/9mQ46MbhvVb4fmIl38MrcvOZNakMUPq1Pbq0HOj0rrszEBh71Vnsii0XcOoVNJr4UPwBqzew45lv+kmx9ovZ/qEhKkbOyWxMEmXXJub8iHX2LyuIjc5m8v23W/2h4J6Uy0Hteu1np9ecX7/2oPf0i8kpXCh6RYsDNMoBekUfDdbpmaJ0unaCfUjnLuASk6QFoI/S6YC4s8plCGO2LhWvSuW0693XudTkNyLfzHVPyZ3gdYrxN5sm4Xw9IrzhywUe5/7K34ZwdhkVfmkU/CjRuj0Hgapc/6yTQ5ApIRrJSIoHbJAeK6hLIRZ7LkSqyWVYsDFf6fhxv6PGjlsUN4aCA/RzHW34o32cWvr+l1IUceXbRzZMLE0ikk6BT9bhI6fnEIPJRF7qXf6iDSeEHJ870LE5owZ44GhE4C3ilVUy8+fzdLrkgmaPEaNHJZ48W+/cJc6RXQ1YgvO1UM6Bb+Q0oZh5My8WRhHGMbwxjHQ/cbAjuF8a/D6KTApGgz98bq+dPe468opFt5Yf2CI/75enAkgSnx72N2K9xy/qyrq+EzsjEomnYI/7wa4/6r4xcfrRyRawLyXOgSlbuwUhgelhNh0U8hENfgO4wjDUJQRDExEBxlJgz+nUILsuPn9wGDB804KbsRL0guX7oYpb2RN1M8G4aY29u7gjdNeGrDJrnqIJfgi8jXgIuAw8Dvg46r6h4DzdgD7gV6gR1Wb4/SbCGGxi2H4/fiD0hMnc7dQRx+v1x3HxLAEZmHJ4d75Ucc/n8mlcztLAPjwG3czWfaxr36ik0qhgJw5uYqIlPpH7m6G8rqMvFa4f0E3irshqNRioZjYGZVMXAv/EeDzmTKHXwE+D3wu5Nz3qurrMftLhk03hUTeCIwYFVzc3Cv2wxsdsXcFNJ8NWllCPQWnrizrW5w2PZWrgMjJ4dyUCaescObVp284P7E0CrkI2nyVrz8/23v+KB6v2BeySBo2/kIijNKOXavKJ5bgq6o37GMLcEm84ZSI0MVLDRD7gAXZI92O6BaSZbL7jQgnDSRC4ycZqfaKfh79LuRxuPW6vNMfR01THOdHnlQKAzfNQpBARxlvWJEV171TCUJm7hIjCZL04V8BtIa8p8BGEVHgDlVdHdaIiLQALQDTpk1LcHge8lq0DXH9uJOGm544Mnm6kgqYXNyNRO+XX3Dj8DuhK7POEDSBFIEgkU065XBYgrUkBTrJCCDDqARyCr6IPAqcEPDWF1T1/sw5XwB6gHtCmjlLVXeJyHHAIyLyW1V9LOjEzGSwGqC5ubk4sY5JFEBxI17yCfEslAL7+OywdYwS36JyxAkkl2WchGXvdflA4ZZ+lN29+aZNjvqZfCikXQt5NJIkp+Cr6rnZ3heRpcCFwDzV4JVQVd2VedwjIhuAOUCg4JeEIF/44T8G+9Ybx0NPd3gVrWx3C0mFbEYMp/T7tydLyJJJKSYphiYrK1bbJoqGEY24UToLcBZpz1HVAyHnHAXUqer+zPP5QL5+kOTx+sLb1zl1YP24i7MQvlCa7W4hktgLNI5znnZ3MmTNIKhEY0R26bFMCRL9kAkkLKtk0njTF0Dx0hDHrUmb9DgKmZAs5NFIkrg+/NuAkThuGoAtqrpcRCYDd6rqQuB4YEPm/WHAD1X15zH7TQ43r45fsKXOCXf0R8j4GXS3kGd45tipQ4uQt6/rn1z21k1k7ajo4ZR+//b6sVdwzYFv5a7xG0A1CUyYKKY902U1/RsapSFulM6fhRzfBSzMPH8JeGecfopKWF4d7YOnfhhYJHwI7t3CimMIX5SNaLl77jyuzvxgCw2pfGLU+7hm3sycYZz5VJyKg78fNy1D3Pai5swpl/AlYaVXo2iX+7obQ0nnTluPFZ01aibfCJkwf74bT5+ruHqGuILlFZjFm6fS6r+LyIG7DuDmxs+n73JSK5Z93GteaROeUTmkT/DDXDhh5LPAGbYT1hX3IoZCxiEo1DFXNsy4/Xhf50suQatUv3eljKPY2IRTuaRP8PMtXp5PwrGIO2FzEVew4vzg3M1L3hQD5fqh5rvjtdqFJSmhrNQJzyg/6RP8fCz2QiJkKtiSz0WphCHJzVdBr5PqxygMm3AqFwkJna8Impubta2tLdlGbz05ET97NZDUHYK7uFqsH26QcHv3E0BwnpywNMdRxpvr2pRTrJJyeZVbaCtlHGlDRLaGJahMn4VfpX72WsKEIB3Yv2/lkT4LHwZH6dSAJV8sip1iwCXMMs/lwy8koVuuu5dS390kSTWP3UgOs/D9mCVfFvyCFKVe7IFDPUPy0+eqTVtM7O7EqGbSKfhGJIotav6NXUEJ2vIR8yRSFVTzgmM1j90oDSb4RsnIJwVCthDFcgibxZYbtYAJfrVRg+sP5RDNXH1Ws5BX89iN4pLORdtqJWiX8PBGuGhl1Yt+GMWwpOO0aZa9UelkW7StK/VgjBgE7RJ28/0YhmHkwCz8aiI0G6fAij+UejRVh4UtGmnALPxaISyvTz75foyqYvEdm6s++6dROdiibTWRbZewkZNqC1ssVl0CI73EsvBFZIWI/F5EtmX+Foact0BEnheRF0Xk+jh9ppqmRc4C7dipgDiPNbxgWwy8WUArGW8+IbcugVn6RlySsPBvVdVbwt4UkXrg28B5QAfwaxF5QFW3J9B3+rBdwrGJmm65XAQljzNL30iCUrh05gAvZkodIiI/Ai4GTPCNklFtG6e8RWiCMoUWk0q/NkbhJLFoe7WItIvI3SIyLuD9twHefMQdmWOBiEiLiLSJSNvevXsTGJ5hVBfubuIzZowvudgbtU1OC19EHgVOCHjrC8DtwBdxYgW/CPwrcIW/iYDPhsaCqupqYDU4YZm5xmcYUai2BVuXclj21XIXZORPTsFX1XOjNCQi3wF+GvBWBzDV83oKsCvS6AwjxZjQGkkTy4cvIpNUdXfm5YeAZwJO+zUwU0RmAL8HLgU+GqdfwygUE9FwqvUuyIhO3EXbr4rIbBwXzQ5gGYCITAbuVNWFqtojIlcDDwP1wN2q+mzMfg2jajFBNcpFLMFX1b8JOb4LWOh5/SDwYJy+DMMoDTYR1S6209YwSoQtiiaPXcP8sFw6hmEYKcEsfMMoEbYomhx2t1QYZuEbRp5YXhujWjEL3zBKjFmh8bG7pcIwwTeMiJgbwah2TPANw6haanGyLaYhYYJvGBExN4JR7ZjgG4ZhVAClcBma4BtGnphlb1QrJviGYRgVQClchhaHbxiGkRLMwjcMw6ggiukyNAvfMAwjJZjgG4ZhpAQTfMMwjJRggm8YhpESTPANwzBSggm+YRhGShBVLfcYQhGRvcArCTd7LPB6wm1WM3Y9hmLXZCh2TQZTydfjRFWdGPRGRQt+MRCRNlVtLvc4KgW7HkOxazIUuyaDqdbrYS4dwzCMlGCCbxiGkRLSKPiryz2ACsOux1DsmgzFrslgqvJ6pM6HbxiGkVbSaOEbhmGkEhN8wzCMlJBKwReRFSLyexHZlvlbWO4xlQMRWSAiz4vIiyJyfbnHUwmIyA4ReTrz/6Kt3OMpNSJyt4jsEZFnPMfGi8gjIvJC5nFcOcdYakKuSVVqSCoFP8Otqjo78/dguQdTakSkHvg2cAEwC1giIrPKO6qK4b2Z/xdVF2edAGuABb5j1wObVHUmsCnzOk2sYeg1gSrUkDQLftqZA7yoqi+p6mHgR8DFZR6TUWZU9TGg03f4YuB7meffAz5Y0kGVmZBrUpWkWfCvFpH2zO1aqm5RM7wN2Ol53ZE5lnYU2CgiW0WkpdyDqRCOV9XdAJnH48o8nkqh6jSkZgVfRB4VkWcC/i4Gbgf+FJgN7Ab+tayDLQ8ScMxidOEsVT0Vx9V1lYi8p9wDMiqSqtSQmq1pq6rnRjlPRL4D/LTIw6lEOoCpntdTgF1lGkvFoKq7Mo97RGQDjuvrsfKOquy8JiKTVHW3iEwC9pR7QOVGVV9zn1eThtSshZ+NzH9alw8Bz4SdW8P8GpgpIjNEZARwKfBAmcdUVkTkKBEZ7T4H5pPO/xt+HgCWZp4vBe4v41gqgmrVkJq18HPwVRGZjePC2AEsK+9wSo+q9ojI1cDDQD1wt6o+W+ZhlZvjgQ0iAs5v44eq+vPyDqm0iMhaYC5wrIh0ADcCNwPrRORvgVeBj5RvhKUn5JrMrUYNsdQKhmEYKSGVLh3DMIw0YoJvGIaREkzwDcMwUoIJvmEYRkowwTcMw0gJJviGYRgpwQTfMAwjJfx/aFiFfQLDR4wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_scaled = preprocessing.scale(x[:,:-1]) # We remove the indexing and make sure all the features are in N(0,1)\n",
    "x_reduced = pca.fit_transform(x_scaled)\n",
    "\n",
    "print(x_scaled.shape)\n",
    "print(x_reduced.shape)\n",
    "\n",
    "plt.scatter(x_reduced[:,0][y==0], x_reduced[:,1][y==0], marker='+', label='Negative')\n",
    "plt.scatter(x_reduced[:,0][y==1], x_reduced[:,1][y==1], marker='o', label='positive')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the entropy. The input is a column vector of target class values, and the output is its entropy.\n",
    "\n",
    "`y` is an `n X 1` sized matrix where `n` is the number of data points (targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9526351224018599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_entropy(y):\n",
    "\n",
    "    uniqueY = np.unique(y,return_counts=True)\n",
    "\n",
    "    countY = y.shape[0]\n",
    "\n",
    "    if len(uniqueY[0])<2:\n",
    "        return 0\n",
    "    else:\n",
    "        firstClass = uniqueY[0][0]\n",
    "        firstProb = uniqueY[1][0].astype(float)/countY\n",
    "\n",
    "        secClass = uniqueY[1][0]\n",
    "        secProb = uniqueY[1][1].astype(float)/countY\n",
    "    return -1*(firstProb*np.log2(firstProb) + secProb*np.log2(secProb))\n",
    "\n",
    "print(calculate_entropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next using the`calculate_entropy()`function we can create the complete the find_split(x, y)`function.\n",
    "\n",
    "`find_split(x, y)` takes as input:\n",
    " * The data matrix of features, `x` in `R^{nXd}`. `n` is the number of data points and `d` is the feature dimensionality. \n",
    " * `y`, a column vector of size `n` containing the target value for each data point in `x`.\n",
    "\n",
    "`find_split(x, y)` outputs 'best_split' which is a dictionary with the following keys and their corresponding values:\n",
    "\n",
    " * `'feature'`: An integer indexing the attribute/feature chosen to split upon.\n",
    " * `'split'`: The value/threshold of this feature to split at.\n",
    " * `'infogain'`: A scalar representing the amount of information gained by splitting this way.\n",
    " * `'left_indices'`: Indices of the exemplars that satisfy `x[feature_index]<=split`.\n",
    " * `'right_indices'`: Opposite set of indices to `left_indices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 22,\n",
       " 'split': 105.0,\n",
       " 'infogain': 0.6180372496508715,\n",
       " 'left_indices': array([  3,   5,   9,  19,  20,  21,  37,  38,  40,  41,  46,  47,  48,\n",
       "         49,  50,  51,  52,  55,  58,  59,  60,  61,  63,  66,  67,  68,\n",
       "         69,  71,  74,  76,  79,  80,  81,  84,  88,  90,  92,  93,  96,\n",
       "         97,  98, 101, 102, 103, 104, 106, 107, 109, 110, 111, 113, 114,\n",
       "        115, 116, 120, 123, 124, 125, 130, 135, 136, 137, 139, 140, 142,\n",
       "        143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 155, 158, 159,\n",
       "        160, 163, 165, 166, 169, 170, 173, 174, 175, 176, 178, 179, 183,\n",
       "        185, 187, 188, 189, 191, 192, 193, 195, 200, 204, 206, 208, 211,\n",
       "        215, 216, 217, 220, 221, 222, 224, 226, 228, 231, 232, 234, 235,\n",
       "        238, 240, 241, 242, 243, 245, 246, 247, 248, 249, 251, 266, 267,\n",
       "        268, 269, 270, 271, 273, 275, 276, 278, 279, 281, 284, 285, 286,\n",
       "        287, 288, 289, 290, 292, 293, 294, 295, 296, 297, 299, 301, 303,\n",
       "        304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "        318, 319, 320, 322, 324, 325, 326, 327, 331, 332, 333, 334, 336,\n",
       "        338], dtype=int64),\n",
       " 'right_indices': array([  0,   1,   2,   4,   6,   7,   8,  10,  11,  12,  13,  14,  15,\n",
       "         16,  17,  18,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
       "         32,  33,  34,  35,  36,  39,  42,  43,  44,  45,  53,  54,  56,\n",
       "         57,  62,  64,  65,  70,  72,  73,  75,  77,  78,  82,  83,  85,\n",
       "         86,  87,  89,  91,  94,  95,  99, 100, 105, 108, 112, 117, 118,\n",
       "        119, 121, 122, 126, 127, 128, 129, 131, 132, 133, 134, 138, 141,\n",
       "        147, 148, 156, 157, 161, 162, 164, 167, 168, 171, 172, 177, 180,\n",
       "        181, 182, 184, 186, 190, 194, 196, 197, 198, 199, 201, 202, 203,\n",
       "        205, 207, 209, 210, 212, 213, 214, 218, 219, 223, 225, 227, 229,\n",
       "        230, 233, 236, 237, 239, 244, 250, 252, 253, 254, 255, 256, 257,\n",
       "        258, 259, 260, 261, 262, 263, 264, 265, 272, 274, 277, 280, 282,\n",
       "        283, 291, 298, 300, 302, 317, 321, 323, 328, 329, 330, 335, 337,\n",
       "        339, 340], dtype=int64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def find_split(x, y):\n",
    "    \"\"\"Given a dataset and its target values, this finds the optimal combination\n",
    "    of feature and split point that gives the maximum information gain.\"\"\"\n",
    "\n",
    "    yCount = len(y)\n",
    "    \n",
    "    # Need the starting entropy so we can measure improvement...\n",
    "    start_entropy = calculate_entropy(y)\n",
    "    \n",
    "    # Best thus far, initialised to a dud that will be replaced immediately...\n",
    "    best = {'infogain' : -np.inf}\n",
    "    \n",
    "    # Loop every possible split of every dimension...\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "\n",
    "        for split in np.unique(x[:,i]):\n",
    "\n",
    "            left_indices = np.where(x[:,i]<=split)[0]\n",
    "            right_indices = np.where(x[:,i]>split)[0]\n",
    "\n",
    "            leftEntropy = calculate_entropy(y[left_indices])\n",
    "            leftCount = len(left_indices)\n",
    "            rightEntropy = calculate_entropy(y[right_indices])\n",
    "            rightCount = len(right_indices)\n",
    "\n",
    "            infogain = start_entropy - ((leftCount/yCount)*leftEntropy) -((rightCount/yCount)*rightEntropy)\n",
    "            \n",
    "            if infogain > best['infogain']:\n",
    "                best = {'feature' : i,\n",
    "                        'split' : split,\n",
    "                        'infogain' : infogain, \n",
    "                        'left_indices' : left_indices,\n",
    "                        'right_indices' : right_indices}\n",
    "    return best\n",
    "\n",
    "find_split(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The function `find_split()` allows us to find the optimal feature and the best value to split the data into two chunks. Applying this to the original data set splits it into two new data sets. We can then repeat this on both of the new data sets to get four data sets, and so on. This recursion builds a decision tree. It needs a stopping condition, to prevent it dividing the data forever, here we will use two:\n",
    " * Maximum depth: The tree is limited to be no deeper than a provided limit.\n",
    " * Perfection: If a node contains only one class then there is little point in splitting it further.\n",
    "\n",
    "We build the function `build_tree(x, y, max_depth)` below to construct a tree. The inputs are: \n",
    "\n",
    " * The data matrix of features, `x` in `R^{nXd}`. `n` is the number of data points and `d` is the feature dimensionality. \n",
    " * `y`, a column vector of size `n` containing the target value for each data point in `x`.\n",
    " * The maximum depth of the tree, `max_depth`.\n",
    "\n",
    "The output of this function is a dictionary. If it has generated a leaf node then the keys are:\n",
    " * `'leaf' : True`\n",
    " * `'class'` : The index of the class to assign to exemplars that land here.\n",
    "\n",
    "If it has generated a split node then the keys are:\n",
    " * `'leaf' : False`\n",
    " * `'feature'`: The feature to apply the `split` to.\n",
    " * `'split'`: The split to test the exemplars `feature` with.\n",
    " * `'infogain'`: The information gain of this split.\n",
    " * `'left'` : The left subtree, for exemplars where `x[feature_index]<=split`\n",
    " * `'right'` : The right subtree, for exemplars where `x[feature_index]>split`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(x, y, max_depth = np.inf):\n",
    "    # Check if either of the stopping conditions have been reached. If so generate a leaf node...\n",
    "    #check if y within std band\n",
    "\n",
    "    if max_depth==1 or (y==y[0]).all():\n",
    "        # Generate a leaf node...\n",
    "        #change for regression to make make leaf mean f y\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        return {'leaf' : True, 'class' : classes[np.argmax(counts)]}\n",
    "    \n",
    "    else:\n",
    "        move = find_split(x, y)\n",
    "        \n",
    "        left = build_tree(x[move['left_indices'],:], y[move['left_indices']], max_depth - 1)\n",
    "        right = build_tree(x[move['right_indices'],:], y[move['right_indices']], max_depth - 1)\n",
    "        \n",
    "        return {'leaf' : False,\n",
    "                'feature' : move['feature'],\n",
    "                'split' : move['split'],\n",
    "                'infogain' : move['infogain'],\n",
    "                'left' : left,\n",
    "                'right' : right}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After building the tree we should be able to predict the class of a sample. We do that by propagating the sample through the tree, i.e. we check all the splitting conditions until the sample falls in a leaf node, in which case the class of the leaf node is attributed to the sample.\n",
    "\n",
    "We provide the recursive function `predict_one(tree, sample)` that takes as input the constructed tree, a sample in `R^d` and recursively propagates it through the branches of our tree. The output of this function is the class predicted for the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(tree, sample):\n",
    "    \"\"\"Does the prediction for a single data point\"\"\"\n",
    "    if tree['leaf']:\n",
    "        return tree['class']\n",
    "    \n",
    "    else:\n",
    "        if sample[tree['feature']] <= tree['split']:\n",
    "            return predict_one(tree['left'], sample)\n",
    "        else:\n",
    "            return predict_one(tree['right'], sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further generalize the prediction function above to the case where we have a data matrix `R^{nXd}` representing many data points. the function `predict(tree, samples)` below takes as input the constructed tree and a data array then returns an array containing the predictions for all the samples in our input data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, samples):\n",
    "    \"\"\"Predicts class for every entry of a data matrix.\"\"\"\n",
    "    ret = np.empty(samples.shape[0], dtype=int)\n",
    "    ret.fill(-1)\n",
    "    indices = np.arange(samples.shape[0])\n",
    "    \n",
    "    def tranverse(node, indices):\n",
    "   \n",
    "        nonlocal samples\n",
    "        nonlocal ret\n",
    "        \n",
    "        if node['leaf']:\n",
    "            ret[indices] = node['class']\n",
    "        \n",
    "        else:\n",
    "            going_left = samples[indices, node['feature']] <= node['split']\n",
    "            left_indices = indices[going_left]\n",
    "            right_indices = indices[np.logical_not(going_left)]\n",
    "            \n",
    "            if left_indices.shape[0] > 0:\n",
    "                tranverse(node['left'], left_indices)\n",
    "                \n",
    "            if right_indices.shape[0] > 0:\n",
    "                tranverse(node['right'], right_indices)\n",
    "    \n",
    "    tranverse(tree, indices)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = build_tree(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next using the functions above can build a tree and report the training and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tree1 = build_tree(x_train,y_train)\n",
    "predictRes = predict(tree1, x_train)\n",
    "\n",
    "correct = len(np.where(predictRes[:]==y_train[:])[0])\n",
    "\n",
    "total = len(x_train[:,0])\n",
    "\n",
    "accuracy = correct/total\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf': False, 'feature': 22, 'split': 105.0, 'infogain': 0.6180372496508715, 'left': {'leaf': False, 'feature': 24, 'split': 0.1733, 'infogain': 0.14260717506536755, 'left': {'leaf': False, 'feature': 21, 'split': 23.31, 'infogain': 0.046686955553979476, 'left': {'leaf': True, 'class': 1}, 'right': {'leaf': False, 'feature': 27, 'split': 0.1282, 'infogain': 0.1084651853828234, 'left': {'leaf': False, 'feature': 15, 'split': 0.01202, 'infogain': 0.10581875923418943, 'left': {'leaf': False, 'feature': 7, 'split': 0.02645, 'infogain': 0.43714361201868296, 'left': {'leaf': False, 'feature': 11, 'split': 0.8265, 'infogain': 0.3095434291503252, 'left': {'leaf': True, 'class': 0}, 'right': {'leaf': True, 'class': 1}}, 'right': {'leaf': True, 'class': 0}}, 'right': {'leaf': True, 'class': 1}}, 'right': {'leaf': True, 'class': 0}}}, 'right': {'leaf': True, 'class': 0}}, 'right': {'leaf': False, 'feature': 22, 'split': 114.3, 'infogain': 0.15946418150236125, 'left': {'leaf': False, 'feature': 1, 'split': 19.65, 'infogain': 0.61751117056093, 'left': {'leaf': False, 'feature': 0, 'split': 13.96, 'infogain': 0.7219280948873623, 'left': {'leaf': True, 'class': 0}, 'right': {'leaf': True, 'class': 1}}, 'right': {'leaf': True, 'class': 0}}, 'right': {'leaf': False, 'feature': 7, 'split': 0.02771, 'infogain': 0.06722154475830686, 'left': {'leaf': True, 'class': 1}, 'right': {'leaf': True, 'class': 0}}}}\n"
     ]
    }
   ],
   "source": [
    "print(tree1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can experiment to find the best `max_depth` parameter. We will test over the range 2 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "bestMax_depth = 0\n",
    "bestAccuracy = 0\n",
    "for max_depth in range(2,6):\n",
    "    tree = build_tree(x_train,y_train,max_depth)\n",
    "    predictRes = predict(tree, x_test)\n",
    "    correct = len(np.where(predictRes[:]==y_test[:])[0])\n",
    "    total = len(x_train[:,0])\n",
    "    accuracy = correct/total\n",
    "    if accuracy>bestAccuracy:\n",
    "        bestMax_depth = max_depth\n",
    "        bestAccuracy = accuracy\n",
    "    \n",
    "print(bestMax_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can write a recursive function that prints out the best tree learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x 22 <= 105.0\n",
      "           x 24 <= 0.1733\n",
      "               x 21 <= 23.31\n",
      "                   predict 1\n",
      "               x 21 > 23.31\n",
      "                   predict 1\n",
      "           x 24 > 0.1733\n",
      "               predict 0\n",
      "       x 22 > 105.0\n",
      "           x 22 <= 114.3\n",
      "               x 1 <= 19.65\n",
      "                   predict 1\n",
      "               x 1 > 19.65\n",
      "                   predict 0\n",
      "           x 22 > 114.3\n",
      "               x 7 <= 0.02771\n",
      "                   predict 1\n",
      "               x 7 > 0.02771\n",
      "                   predict 0\n"
     ]
    }
   ],
   "source": [
    "def print_tree(tree1, indent = 0):\n",
    "    indent = indent+4\n",
    "    if tree1['leaf']==False:\n",
    "        print(' '*indent, 'x',tree1['feature'], '<=',tree1['split'])\n",
    "        print_tree(tree1['left'],indent)\n",
    "        \n",
    "        print(' '*indent,'x',tree1['feature'], '>',tree1['split'])\n",
    "        print_tree(tree1['right'],indent)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print (' '*indent,'predict',tree1['class'])\n",
    "    \n",
    "\n",
    "tree1 = build_tree(x_train,y_train,4)\n",
    "print_tree(tree1,2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
